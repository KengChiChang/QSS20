{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"collections/staff/kengchi/","text":"Hey, I\u2019m Keng-Chi! I am an Assistant Professor in Quantitative Social Science at Dartmouth. I use computational tools, including AI and Large Language Models, to study how technology and media influence politics. My work explores censorship circumvention, online image-sharing behavior, and how short-form video content are recommended by algorithms. I\u2019m fascinated by the ways our digital world is reshaping democracy and the possibilities\u2014and risks\u2014it creates for our social life. Outside of work, I love hiking, arthouse movies, and cooking Taiwanese food.","title":"Kengchi"},{"location":"collections/staff/grace/","text":"The Social Science Data Lab is an initiative that advances data-driven research in the social sciences by acting as a resource for students and faculty in Economics, Government, and Quantitative Social Science. The SSDL provides comprehensive support throughout the quantitative research process, from initial planning and design to final analysis, interpretation, and presentation. The lab is staffed by Data Scientists proficient in Python, R, and Stata. Feel free to seek out help for assignments and your final project.","title":"Grace"},{"location":"","text":"Topic Homeworks Project Week 1 Tue 9/16 Course intro & syllabus review lesson: slides Thu 9/18 Python basics & software setup lesson: slides lecture activity datacamp: videos Introduction to Python: Python Basics Introduction to Python: Python Lists Introduction to Python: Functions and Packages Release HW1 Problem Set 1 Due 11:59 pm Week 2 Tue 9/23 Pandas for data manipulation 1 lesson: slides activity datacamp: videos Data Manipulation with pandas: Transforming DataFrames Data Manipulation with pandas: Aggregating DataFrames Data Manipulation with pandas: Slicing and Indexing DataFrames Thu 9/25 Pandas 2 + data visualization lesson: slides notebook datacamp: videos Data Manipulation with pandas: Creating and Visualizing DataFrames Week 3 Tue 9/30 User-defined functions, Workflow: Command line lesson: slides notebook datacamp: videos Writing your own functions Introduction to Shell Release Project preference survey Due 11:59 pm Thu 10/2 Workflow: Git & GitHub lesson: slides notebook datacamp: videos Introduction to GitHub Release HW2 Problem Set 2 Due 11:59 pm Week 4 Tue 10/7 Reshaping & merging data lesson: slides notebook datacamp: videos Data Merging Basics Merging Tables With Different Join Types Thu 10/9 SQL & LaTeX lesson: slides notebook datacamp: videos Introduction to SQL Week 5 Tue 10/14 Reading flat files, Regular expressions (Regex) lesson: slides notebook datacamp: videos Streamlined Data Ingestion with pandas: Importing Data from Flat Files Regular Expressions for Pattern Matching Release Final project milestone 1 Due 11:59 pm Thu 10/16 Text as data 1 (text mining) lesson: slides notebook datacamp: videos Natural Language Processing (NLP) in Python: Text Processing Fundamentals Natural Language Processing (NLP) in Python: Feature Extraction from Text Release HW3 Problem Set 3 Due 11:59 pm Week 6 Tue 10/21 Text as data 2 (topic modeling) lesson: slides notebook datacamp: videos Natural Language Processing (NLP) in Python: Text Classification with Hugging Face Natural Language Processing (NLP) in Python: Token Classification and Text Generation Thu 10/23 APIs 1 (NAEP & Yelp) lesson: slides notebook datacamp: videos Streamlined Data Ingestion with pandas: Importing JSON Data and Working with APIs Introduction to APIs in Python: Making API Requests with Python Week 7 Tue 10/28 APIs 2 (ChatGPT) lesson: slides notebook datacamp: videos Introduction to APIs in Python: More API request concepts Release Final project milestone 2 Due 11:59 pm Thu 10/30 Supervised machine learning lesson: slides notebook datacamp: videos Supervised Learning with scikit-learn Release HW4 Problem Set 4 Due 11:59 pm Week 8 Tue 11/4 Unsupervised machine learning lesson: slides notebook datacamp: videos Unsupervised Learning in Python Thu 11/6 Social network visualization lesson: slides notebook Week 9 Tue 11/11 Final project work session Thu 11/13 Final presentations Release Final project presentation Due 11:59 pm Week 10 Tue 11/18 Final presentations Release Final report Submission Due 11:59 pm","title":"\ud83c\udfe1 Home"},{"location":"acknowledgements/","text":"This website is generated by mkdocs . The text is set in the Inter font family by Rasmus Andersson. This website template was developed for CSE 373 at University of Washington by Brian Chan, Maia Xiao, and Aaron Johnston with modifications by Hunter Schafer. The theme for the course website draws inspiration from Just the Class , with thanks to its author Kevin Lin.","title":"Acknowledgements"},{"location":"data/","text":"Texts \u00b6 Trump Tweet Archive US Newspapers 1780-1960 US Congressinal Record 1873-2017 Wikipedia Dumps Upworthy News Archive The Great Firewall\u2019s Largest Document Leak Images \u00b6 US Presidential Candidates\u2019 Facebook and Instagram Images in the 2020 US Election Hateful Memes Challenge Dataset Python Package for Bing Image Search Protest Images Multimodal \u00b6 Political Advertisements from Facebook Reddit Dumps Sources to Find Data \u00b6 Harvard Dataverse ProPublica Data Store ICPSR Hugging Face Datasets Google Dataset Search Awesome Public Datasets Paper with Code Datasets","title":"Useful Data Sources"},{"location":"data/#texts","text":"Trump Tweet Archive US Newspapers 1780-1960 US Congressinal Record 1873-2017 Wikipedia Dumps Upworthy News Archive The Great Firewall\u2019s Largest Document Leak","title":"Texts"},{"location":"data/#images","text":"US Presidential Candidates\u2019 Facebook and Instagram Images in the 2020 US Election Hateful Memes Challenge Dataset Python Package for Bing Image Search Protest Images","title":"Images"},{"location":"data/#multimodal","text":"Political Advertisements from Facebook Reddit Dumps","title":"Multimodal"},{"location":"data/#sources-to-find-data","text":"Harvard Dataverse ProPublica Data Store ICPSR Hugging Face Datasets Google Dataset Search Awesome Public Datasets Paper with Code Datasets","title":"Sources to Find Data"},{"location":"debugging/","text":"","title":"\ud83d\udc1e Debugging"},{"location":"evaluations/","text":"Datacamp Modules (5%, by completion) \u00b6 The DataCamp modules are mainly to support your work on the problem sets and final project by giving you additional practice prior to our in-class activities. As a result, they will be graded on a \u201ccomplete\u201d and \u201cincomplete\u201d basis, regardless of how many points you received on the assignment itself. This means that you shouldn\u2019t get stuck partway through, since you can always ask to be shown the answer with a points deduction. Conversely, if the concepts are a review to you, these should be very quick to complete, but if you\u2019d prefer to skip, you can talk to me and I will reapportion the 5% to your problem sets. You will receive full credit for DataCamp modules so long as you complete them by the time your final papers are due. Problem Sets (40%; 10% each) \u00b6 Problem sets will assess your ability to apply the concepts to data that is substantially messier, and problems that are substantially more difficult, than the ones in DataCamp. More details on the problem sets will be provided the week before each is released, but here\u2019s the rough workflow: Access the problem set and data via GitHub or Jhub Work to produce the following outputs for each problem set: * A raw .ipynb with the code for the problem set * A compiled pdf that displays that code and also answers the written questions. These written questions will involve using some LaTeX syntax for equations and formatting. * When applicable (e.g., part of the problem set is run in script form), a supporting .py file The problem sets will be graded on both accuracy and programming style. For instance, by our second problem set, you will have learned to write functions. The problem set will be designed to test those concepts and if you revert, for instance, to writing repeated code that could be replaced with a function, points will be deducted even if that inefficient code arrives at the correct answer. A solution key to each problem set will be posted to the Files area on the Canvas after all students have submitted. Final Project (35%) \u00b6 Final projects will be completed in groups of 2-3. You will work on a project that integrates the concepts we are covering into an applied data science project. The end product will be a final status update presentation, a 8-page scientific report, and a complete GitHub repository. See the \u201cProject Components\u201d page for more information on these outputs. In-Class Quizzes (10%; 1% each) \u00b6 To help you stay engaged and on track with the course materials, there will be short in-class quizzes administered at random during lecture time. Each quiz will be very brief\u2014typically 1\u20132 multiple-choice, Yes/No, or short-answer questions\u2014and designed to be completed in under 3 minutes. These quizzes are meant to be straightforward checks of understanding rather than high-stakes assessments. More quizzes will be given than needed to reach the 10% grade allocation, so missing one or two will not harm your grade. The goal is to encourage consistent participation and regular review of course content. Team Player / Participation (10%) \u00b6 Data science is a highly collaborative activity in the real world, and you should think of your classmates as resources rather than as competition. We will be using a #problemset channel in our class Slack for you to ask questions about roadblocks you encounter with the DataCamp activities or on the problem sets. While I will be answering questions within a window of 24 hours, I encourage you to help each other and answer each other\u2019s questions. Your participation grade will reflect whether you\u2019ve helped your classmates on the forum and your participation in class, which includes: Interacting during class, e.g. asking and answering questions Participation in class coding activities in small groups Contributions to your group\u2019s final project","title":"Evaluations & Grading"},{"location":"evaluations/#datacamp-modules-5-by-completion","text":"The DataCamp modules are mainly to support your work on the problem sets and final project by giving you additional practice prior to our in-class activities. As a result, they will be graded on a \u201ccomplete\u201d and \u201cincomplete\u201d basis, regardless of how many points you received on the assignment itself. This means that you shouldn\u2019t get stuck partway through, since you can always ask to be shown the answer with a points deduction. Conversely, if the concepts are a review to you, these should be very quick to complete, but if you\u2019d prefer to skip, you can talk to me and I will reapportion the 5% to your problem sets. You will receive full credit for DataCamp modules so long as you complete them by the time your final papers are due.","title":"Datacamp Modules (5%, by completion)"},{"location":"evaluations/#problem-sets-40-10-each","text":"Problem sets will assess your ability to apply the concepts to data that is substantially messier, and problems that are substantially more difficult, than the ones in DataCamp. More details on the problem sets will be provided the week before each is released, but here\u2019s the rough workflow: Access the problem set and data via GitHub or Jhub Work to produce the following outputs for each problem set: * A raw .ipynb with the code for the problem set * A compiled pdf that displays that code and also answers the written questions. These written questions will involve using some LaTeX syntax for equations and formatting. * When applicable (e.g., part of the problem set is run in script form), a supporting .py file The problem sets will be graded on both accuracy and programming style. For instance, by our second problem set, you will have learned to write functions. The problem set will be designed to test those concepts and if you revert, for instance, to writing repeated code that could be replaced with a function, points will be deducted even if that inefficient code arrives at the correct answer. A solution key to each problem set will be posted to the Files area on the Canvas after all students have submitted.","title":"Problem Sets (40%; 10% each)"},{"location":"evaluations/#final-project-35","text":"Final projects will be completed in groups of 2-3. You will work on a project that integrates the concepts we are covering into an applied data science project. The end product will be a final status update presentation, a 8-page scientific report, and a complete GitHub repository. See the \u201cProject Components\u201d page for more information on these outputs.","title":"Final Project (35%)"},{"location":"evaluations/#in-class-quizzes-10-1-each","text":"To help you stay engaged and on track with the course materials, there will be short in-class quizzes administered at random during lecture time. Each quiz will be very brief\u2014typically 1\u20132 multiple-choice, Yes/No, or short-answer questions\u2014and designed to be completed in under 3 minutes. These quizzes are meant to be straightforward checks of understanding rather than high-stakes assessments. More quizzes will be given than needed to reach the 10% grade allocation, so missing one or two will not harm your grade. The goal is to encourage consistent participation and regular review of course content.","title":"In-Class Quizzes (10%; 1% each)"},{"location":"evaluations/#team-player-participation-10","text":"Data science is a highly collaborative activity in the real world, and you should think of your classmates as resources rather than as competition. We will be using a #problemset channel in our class Slack for you to ask questions about roadblocks you encounter with the DataCamp activities or on the problem sets. While I will be answering questions within a window of 24 hours, I encourage you to help each other and answer each other\u2019s questions. Your participation grade will reflect whether you\u2019ve helped your classmates on the forum and your participation in class, which includes: Interacting during class, e.g. asking and answering questions Participation in class coding activities in small groups Contributions to your group\u2019s final project","title":"Team Player / Participation (10%)"},{"location":"git/","text":"macOS (with Homebrew) \u00b6 Open the Terminal apps such as iterm2 , Ghostty , or Terminal , then run: # install Homebrew if you don't have it /bin/bash -c \" $( curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh ) \" # install git brew install git git --version Windows (in Windows Terminal) \u00b6 Open Windows Terminal (PowerShell profile is fine), then choose one of these: A) winget (built-in on modern Windows) winget install - -id Git . Git -e git - -version B) Chocolatey Set-ExecutionPolicy Bypass -Scope Process -Force [System.Net.ServicePointManager] :: SecurityProtocol = [System.Net.SecurityProtocolType] :: Tls12 iwr https :// community . chocolatey . org / install . ps1 -UseBasicParsing | iex choco install git -y git - -version C) Scoop (user-space, no admin) iwr -useb get . scoop . sh | iex scoop install git git - -version One-time Git setup (do this on every machine) \u00b6 Set your identity and defaults: git config --global user.name \"Your Name\" git config --global user.email \"you@example.com\" git config --global init.defaultBranch main Line endings (prevents Windows/mac newline headaches): macOS/Linux: git config --global core.autocrlf input * Windows: git config - -global core . autocrlf true Optional but useful: git config --global pull.rebase false git config --global color.ui auto (Optional) Set up SSH keys for GitHub/GitLab \u00b6 Generate a key: ssh-keygen -t ed25519 -C \"you@example.com\" # press Enter to accept defaults and set a passphrase if you want Start the agent and add your key: macOS: eval \" $( ssh-agent -s ) \" ssh-add ~/.ssh/id_ed25519 Windows PowerShell (Git Bash also works): eval \" $( ssh-agent -s ) \" ssh-add ~/. ssh / id_ed25519 Copy the public key to your clipboard and add it to your Git hosting account: cat ~/.ssh/id_ed25519.pub Quick test \u00b6 git clone https://github.com/KengChiChang/QSS20_FA25.git cd QSS20_FA25 git log -1","title":"Git and GitHub"},{"location":"git/#macos-with-homebrew","text":"Open the Terminal apps such as iterm2 , Ghostty , or Terminal , then run: # install Homebrew if you don't have it /bin/bash -c \" $( curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh ) \" # install git brew install git git --version","title":"macOS (with Homebrew)"},{"location":"git/#windows-in-windows-terminal","text":"Open Windows Terminal (PowerShell profile is fine), then choose one of these: A) winget (built-in on modern Windows) winget install - -id Git . Git -e git - -version B) Chocolatey Set-ExecutionPolicy Bypass -Scope Process -Force [System.Net.ServicePointManager] :: SecurityProtocol = [System.Net.SecurityProtocolType] :: Tls12 iwr https :// community . chocolatey . org / install . ps1 -UseBasicParsing | iex choco install git -y git - -version C) Scoop (user-space, no admin) iwr -useb get . scoop . sh | iex scoop install git git - -version","title":"Windows (in Windows Terminal)"},{"location":"git/#one-time-git-setup-do-this-on-every-machine","text":"Set your identity and defaults: git config --global user.name \"Your Name\" git config --global user.email \"you@example.com\" git config --global init.defaultBranch main Line endings (prevents Windows/mac newline headaches): macOS/Linux: git config --global core.autocrlf input * Windows: git config - -global core . autocrlf true Optional but useful: git config --global pull.rebase false git config --global color.ui auto","title":"One-time Git setup (do this on every machine)"},{"location":"git/#optional-set-up-ssh-keys-for-githubgitlab","text":"Generate a key: ssh-keygen -t ed25519 -C \"you@example.com\" # press Enter to accept defaults and set a passphrase if you want Start the agent and add your key: macOS: eval \" $( ssh-agent -s ) \" ssh-add ~/.ssh/id_ed25519 Windows PowerShell (Git Bash also works): eval \" $( ssh-agent -s ) \" ssh-add ~/. ssh / id_ed25519 Copy the public key to your clipboard and add it to your Git hosting account: cat ~/.ssh/id_ed25519.pub","title":"(Optional) Set up SSH keys for GitHub/GitLab"},{"location":"git/#quick-test","text":"git clone https://github.com/KengChiChang/QSS20_FA25.git cd QSS20_FA25 git log -1","title":"Quick test"},{"location":"overview/","text":"Course Description \u00b6 QSS 20 is a foundational and required course in the Quantitative Social Science curriculum that equips students with computing literacy to conduct social science research in the age of \u201cbig data.\u201d The skills students learn in QSS 20 are building blocks for data science applications from research to industry to nonprofits and government. This course builds on students\u2019 introductory programming course and teaches you how to draw meaningful insights from real-world, often messy datasets, so you can help incorporate data into decision-making and analysis. The course will teach students to quickly pick up new methods and find patterns in large-scale data\u2014essential skills given that methods and tools for modern statistical computing develop at a rapid pace, and in real-world data science you sometimes don\u2019t know what tools you need to know until you need to know them. Our topics will include data wrangling and visualization, including merging datasets and SQL for database manipulation; data extraction via APIs and web-scraping; processing and analyzing text as data; and supervised machine learning. Students will also be exposed to Git/GitHub for version control and reproducibility, the command line for scalable computing, and LaTeX for smart typesetting and collaborative workflows. In addition to introductory coding modules via DataCamp, in-class activities, and problem sets, the course will culminate in a group-based, applied data science project using a real-world dataset with social impact. Prerequisites \u00b6 The course will move fast, cover a lot of material, and require active engagement with applied projects. To ensure your success, students must have taken or received AP credit for COSC 1, ENGS 20, or equivalent (with QSS chair\u2019s permission) in order to enroll. An introductory statistics course is also recommended. Learning Objectives \u00b6 The goal of this course is for students to become the best data scientists at working with social data. Students will be able to do the following in Python: Work with and visualize various data structures, in particular DataFrames Write effective and well-documented user-defined functions Write API queries to access and custom-build databases Articulate research questions and answer them through cross-sectional analysis or regression Write SQL queries to pull, aggregate, and summarize data stored in database tables Course Sessions \u00b6 Class meetings will typically consist of a lecture (~40 minutes) followed by an in-class tutorial, interactive group activity, and occasional quizzes. In-person attendance is required to get the most out of these group exercises.","title":"Course Overview"},{"location":"overview/#course-description","text":"QSS 20 is a foundational and required course in the Quantitative Social Science curriculum that equips students with computing literacy to conduct social science research in the age of \u201cbig data.\u201d The skills students learn in QSS 20 are building blocks for data science applications from research to industry to nonprofits and government. This course builds on students\u2019 introductory programming course and teaches you how to draw meaningful insights from real-world, often messy datasets, so you can help incorporate data into decision-making and analysis. The course will teach students to quickly pick up new methods and find patterns in large-scale data\u2014essential skills given that methods and tools for modern statistical computing develop at a rapid pace, and in real-world data science you sometimes don\u2019t know what tools you need to know until you need to know them. Our topics will include data wrangling and visualization, including merging datasets and SQL for database manipulation; data extraction via APIs and web-scraping; processing and analyzing text as data; and supervised machine learning. Students will also be exposed to Git/GitHub for version control and reproducibility, the command line for scalable computing, and LaTeX for smart typesetting and collaborative workflows. In addition to introductory coding modules via DataCamp, in-class activities, and problem sets, the course will culminate in a group-based, applied data science project using a real-world dataset with social impact.","title":"Course Description"},{"location":"overview/#prerequisites","text":"The course will move fast, cover a lot of material, and require active engagement with applied projects. To ensure your success, students must have taken or received AP credit for COSC 1, ENGS 20, or equivalent (with QSS chair\u2019s permission) in order to enroll. An introductory statistics course is also recommended.","title":"Prerequisites"},{"location":"overview/#learning-objectives","text":"The goal of this course is for students to become the best data scientists at working with social data. Students will be able to do the following in Python: Work with and visualize various data structures, in particular DataFrames Write effective and well-documented user-defined functions Write API queries to access and custom-build databases Articulate research questions and answer them through cross-sectional analysis or regression Write SQL queries to pull, aggregate, and summarize data stored in database tables","title":"Learning Objectives"},{"location":"overview/#course-sessions","text":"Class meetings will typically consist of a lecture (~40 minutes) followed by an in-class tutorial, interactive group activity, and occasional quizzes. In-person attendance is required to get the most out of these group exercises.","title":"Course Sessions"},{"location":"project/","text":"As the cornerstone achievement of this course, the final research project integrates course concepts into an applied data science project. You will select a data source to investigate, begin with broad questions, and focus on narrowing these down to complete and clearly explain a scientific investigation that applies the programming skills we\u2019ve developed. Your final project will produce three outputs: a status update presentation (on the last day of class), a scientific report (~8 pages), and a GitHub repository. You will also complete two project milestones in the second half of the quarter, for which you\u2019ll be assigned into groups of 2-3 students. You\u2019ll work from a common repository that you\u2019ll be added to, and have push/commit privileges for, when you\u2019re set up on GitHub. Options for working on final projects \u00b6 You will have four options for how you work on the final project, two of which involve forming groups of 2-3 students (we\u2019ll ask you about your preferences later). Choose your own groups Keep in mind complementary skillsets as well as people you like, given how much time you will spend communicating and working together. This project calls for not only people skilled at writing Python code, but also people who excel at doing research, analysis, interpretation, and data visualization. In other words, aim for a diverse team and you will probably find it makes you more productive. Opt into group matching (or recruit 1-2 more) We will account for your matching preferences and restrictions Work alone on a significant, independent project (e.g., Senior Thesis) See the Final Project Options page for more info on this option","title":"Overview"},{"location":"project/#options-for-working-on-final-projects","text":"You will have four options for how you work on the final project, two of which involve forming groups of 2-3 students (we\u2019ll ask you about your preferences later). Choose your own groups Keep in mind complementary skillsets as well as people you like, given how much time you will spend communicating and working together. This project calls for not only people skilled at writing Python code, but also people who excel at doing research, analysis, interpretation, and data visualization. In other words, aim for a diverse team and you will probably find it makes you more productive. Opt into group matching (or recruit 1-2 more) We will account for your matching preferences and restrictions Work alone on a significant, independent project (e.g., Senior Thesis) See the Final Project Options page for more info on this option","title":"Options for working on final projects"},{"location":"python/","text":"This guide will walk you through setting up a professional Python environment for data science on your personal computer. Why Bother with a Local Setup? \u00b6 While cloud platforms and virtual machines are convenient, learning to manage your own data science environment is a crucial skill. It empowers you to work independently and troubleshoot problems, which is a significant part of a data scientist\u2019s daily life. Think of the time you spend on this as an investment in your data science education! \ud83e\uddd1\u200d\ud83d\udcbb What We\u2019ll Be Setting Up \u00b6 We\u2019ll be installing a suite of essential tools: Python and the conda package manager : The foundation of our data science toolkit. VS Code : A powerful and popular code editor that integrates well with Git, Python, R, and more. An Augmented Command Line : As a data scientist, you\u2019ll spend a lot of time working in the command line. Instead of sticking with the bare-bones defaults provided by your operating system, it\u2019s worth upgrading to a more capable terminal. This not only improves your efficiency but also helps you understand how the command line works\u2014a critical skill for debugging and troubleshooting. We\u2019ll tackle these one at a time, starting with Python! Installing Python with Miniforge \u00b6 The first step in setting up your machine for this course is to install both Python and a package manager. Unlike R \u2014where you can simply run install.packages() \u2014Python does not include a built-in package management system. To work with common tools like NumPy, Pandas, or Matplotlib, we need an external manager. In this course, we\u2019ll use conda as the default package manager for Python. Why conda Instead of pip ? \u00b6 Python has two major package managers: pip and conda . pip is popular among software engineers and works well for Python-only libraries. conda , however, is better for data science because it can handle large dependencies and non-Python packages (such as compiled C libraries used by NumPy). Importantly, installing conda also gives you access to pip , so you can use either depending on the situation. Why Miniforge? \u00b6 To install conda , there are three common options: Anaconda Miniconda Miniforge After some experience with all three, I strongly recommend Miniforge. Here\u2019s why: Anaconda comes with Python, conda, and dozens of preinstalled packages. While that sounds convenient, it often causes dependency conflicts once you start adding your own packages. Miniforge is a lighter install\u2014it only includes Python and core utilities like conda and pip\u2014so you start clean and avoid many conflicts. Unlike Miniconda, Miniforge defaults to the conda-forge channel, a community-maintained package repository that is usually the most reliable source for up-to-date libraries. If you already have a conda installation (from Anaconda or Miniconda), you are not actively using right now, it might be a good idea to delete it and start fresh. It\u2019s good practice not to be too attached to your Python installations; sometimes, a clean slate is the easiest way to resolve issues. An Important Note on pyenv \u00b6 Miniforge is a substitute for tools like pyenv or venv . Do not install both. Miniforge\u2019s conda can do everything pyenv can and more, including managing multiple environments. Installation Steps \u00b6 Go to the Miniforge download page . Click the link for your operating system. This will download an installer file. For macOS Users \u00b6 Move the downloaded .sh file to your desktop. Open the Terminal application (you can find it in Applications > Utilities ). In the Terminal, type cd ~/desktop and press Enter . Type bash followed by the name of the downloaded file (e.g., bash Miniforge3-MacOSX-arm64.sh ) and press Enter . When asked to review the license agreement, press Enter . Then, type q to exit the text viewer. Type yes and press Enter to accept the license agreement. Press Enter to accept the default installation location. IMPORTANT : At the end of the installation, you\u2019ll be asked, Do you wish to update your shell profile to automatically initialize conda? . You must type yes and press Enter . For Windows Users \u00b6 Run the downloaded .exe file. When asked who to install for, select \u201cJust for me (recommended)\u201d . Accept the default installation location. You\u2019ll see a few checkboxes. Make sure to check the following: Add Miniforge3 to my PATH environment variable (even though it says it\u2019s not recommended). Register Miniforge3 as my default Python 3.12 . It\u2019s also a good idea to check the box to remove the cache. That\u2019s it! You have installed conda and Python Confirm conda is installed \u00b6 macOS / Linux (Terminal) \u00b6 conda --version python --version which conda conda info Windows (PowerShell or CMD) \u00b6 conda --version python --version where conda conda info You should see conda and python versions (no \u201ccommand not found\u201d / \u201cnot recognized\u201d errors). Set up default channel (recommended) \u00b6 # Make conda-forge highest priority conda config --prepend channels conda-forge # Enforce channel priority (prefer conda-forge builds when available) conda config --set channel_priority strict Verify: conda config --show channels conda config --show channel_priority You should see: channels: - conda-forge - defaults channel_priority: strict Create a clean course environment (recommended) \u00b6 All platforms \u00b6 conda create -n qss20 python = 3 .12 conda activate qss20 Verify you\u2019re in it: conda env list # Look for a \"*\" next to qss20 Check all packages that are currently installed in the environment: conda list # Look for a \"*\" next to qss20 Install JupyterLab \u00b6 Prefer conda first \u00b6 conda install jupyterlab notebook ipykernel Confirm: jupyter lab --version jupyter --version Register the environment as a kernel (so editors can pick it) \u00b6 python -m ipykernel install --user --name qss20 --display-name \"Python (QSS20)\" List kernels to confirm: jupyter kernelspec list You should see qss20 . Install common data science packages \u00b6 Inside the qss20 env: conda install pandas numpy matplotlib seaborn plotly Then run: python -c \"import numpy, pandas; print(numpy.__version__); print(pandas.__version__)\" Launch JupyterLab \u00b6 Standard launch \u00b6 jupyter lab JupyterLab should open in your browser (or print a local URL like http://localhost:8888/lab you can click). Stop JupyterLab: go back to the terminal where it\u2019s running and press Ctrl+C (twice if needed), then confirm y if prompted. Use in VS Code (alternative workflow) \u00b6 Install VS Code extensions: Python and Jupyter . Open or create a .ipynb notebook. Click the kernel picker (top right) \u2192 choose Python (qss20) . Run a cell (e.g., print(\"hello\") ). Common \u201cit\u2019s not working\u201d fixes \u00b6 jupyter not found: conda activate qss20 then reinstall jupyterlab in the qss20 environment. Wrong env active: conda info --envs , then conda activate qss20 . Multiple Python installs causing confusion: check path order: macOS/Linux: which python and which jupyter Windows: where python and where jupyter Kernel not showing in Jupyter/VS Code: re-run the kernel registration step and then restart Jupyter/VS Code. That\u2019s it\u2014if they can print versions, see the qss20 kernel, and open JupyterLab, the install was successful.","title":"Python and conda"},{"location":"python/#why-bother-with-a-local-setup","text":"While cloud platforms and virtual machines are convenient, learning to manage your own data science environment is a crucial skill. It empowers you to work independently and troubleshoot problems, which is a significant part of a data scientist\u2019s daily life. Think of the time you spend on this as an investment in your data science education! \ud83e\uddd1\u200d\ud83d\udcbb","title":"Why Bother with a Local Setup?"},{"location":"python/#what-well-be-setting-up","text":"We\u2019ll be installing a suite of essential tools: Python and the conda package manager : The foundation of our data science toolkit. VS Code : A powerful and popular code editor that integrates well with Git, Python, R, and more. An Augmented Command Line : As a data scientist, you\u2019ll spend a lot of time working in the command line. Instead of sticking with the bare-bones defaults provided by your operating system, it\u2019s worth upgrading to a more capable terminal. This not only improves your efficiency but also helps you understand how the command line works\u2014a critical skill for debugging and troubleshooting. We\u2019ll tackle these one at a time, starting with Python!","title":"What We&rsquo;ll Be Setting Up"},{"location":"python/#installing-python-with-miniforge","text":"The first step in setting up your machine for this course is to install both Python and a package manager. Unlike R \u2014where you can simply run install.packages() \u2014Python does not include a built-in package management system. To work with common tools like NumPy, Pandas, or Matplotlib, we need an external manager. In this course, we\u2019ll use conda as the default package manager for Python.","title":"Installing Python with Miniforge"},{"location":"python/#why-conda-instead-of-pip","text":"Python has two major package managers: pip and conda . pip is popular among software engineers and works well for Python-only libraries. conda , however, is better for data science because it can handle large dependencies and non-Python packages (such as compiled C libraries used by NumPy). Importantly, installing conda also gives you access to pip , so you can use either depending on the situation.","title":"Why conda Instead of pip?"},{"location":"python/#why-miniforge","text":"To install conda , there are three common options: Anaconda Miniconda Miniforge After some experience with all three, I strongly recommend Miniforge. Here\u2019s why: Anaconda comes with Python, conda, and dozens of preinstalled packages. While that sounds convenient, it often causes dependency conflicts once you start adding your own packages. Miniforge is a lighter install\u2014it only includes Python and core utilities like conda and pip\u2014so you start clean and avoid many conflicts. Unlike Miniconda, Miniforge defaults to the conda-forge channel, a community-maintained package repository that is usually the most reliable source for up-to-date libraries. If you already have a conda installation (from Anaconda or Miniconda), you are not actively using right now, it might be a good idea to delete it and start fresh. It\u2019s good practice not to be too attached to your Python installations; sometimes, a clean slate is the easiest way to resolve issues.","title":"Why Miniforge?"},{"location":"python/#an-important-note-on-pyenv","text":"Miniforge is a substitute for tools like pyenv or venv . Do not install both. Miniforge\u2019s conda can do everything pyenv can and more, including managing multiple environments.","title":"An Important Note on pyenv"},{"location":"python/#installation-steps","text":"Go to the Miniforge download page . Click the link for your operating system. This will download an installer file.","title":"Installation Steps"},{"location":"python/#for-macos-users","text":"Move the downloaded .sh file to your desktop. Open the Terminal application (you can find it in Applications > Utilities ). In the Terminal, type cd ~/desktop and press Enter . Type bash followed by the name of the downloaded file (e.g., bash Miniforge3-MacOSX-arm64.sh ) and press Enter . When asked to review the license agreement, press Enter . Then, type q to exit the text viewer. Type yes and press Enter to accept the license agreement. Press Enter to accept the default installation location. IMPORTANT : At the end of the installation, you\u2019ll be asked, Do you wish to update your shell profile to automatically initialize conda? . You must type yes and press Enter .","title":"For macOS Users"},{"location":"python/#for-windows-users","text":"Run the downloaded .exe file. When asked who to install for, select \u201cJust for me (recommended)\u201d . Accept the default installation location. You\u2019ll see a few checkboxes. Make sure to check the following: Add Miniforge3 to my PATH environment variable (even though it says it\u2019s not recommended). Register Miniforge3 as my default Python 3.12 . It\u2019s also a good idea to check the box to remove the cache. That\u2019s it! You have installed conda and Python","title":"For Windows Users"},{"location":"python/#confirm-conda-is-installed","text":"","title":"Confirm conda is installed"},{"location":"python/#macos-linux-terminal","text":"conda --version python --version which conda conda info","title":"macOS / Linux (Terminal)"},{"location":"python/#windows-powershell-or-cmd","text":"conda --version python --version where conda conda info You should see conda and python versions (no \u201ccommand not found\u201d / \u201cnot recognized\u201d errors).","title":"Windows (PowerShell or CMD)"},{"location":"python/#set-up-default-channel-recommended","text":"# Make conda-forge highest priority conda config --prepend channels conda-forge # Enforce channel priority (prefer conda-forge builds when available) conda config --set channel_priority strict Verify: conda config --show channels conda config --show channel_priority You should see: channels: - conda-forge - defaults channel_priority: strict","title":"Set up default channel (recommended)"},{"location":"python/#create-a-clean-course-environment-recommended","text":"","title":"Create a clean course environment (recommended)"},{"location":"python/#all-platforms","text":"conda create -n qss20 python = 3 .12 conda activate qss20 Verify you\u2019re in it: conda env list # Look for a \"*\" next to qss20 Check all packages that are currently installed in the environment: conda list # Look for a \"*\" next to qss20","title":"All platforms"},{"location":"python/#install-jupyterlab","text":"","title":"Install JupyterLab"},{"location":"python/#prefer-conda-first","text":"conda install jupyterlab notebook ipykernel Confirm: jupyter lab --version jupyter --version","title":"Prefer conda first"},{"location":"python/#register-the-environment-as-a-kernel-so-editors-can-pick-it","text":"python -m ipykernel install --user --name qss20 --display-name \"Python (QSS20)\" List kernels to confirm: jupyter kernelspec list You should see qss20 .","title":"Register the environment as a kernel (so editors can pick it)"},{"location":"python/#install-common-data-science-packages","text":"Inside the qss20 env: conda install pandas numpy matplotlib seaborn plotly Then run: python -c \"import numpy, pandas; print(numpy.__version__); print(pandas.__version__)\"","title":"Install common data science packages"},{"location":"python/#launch-jupyterlab","text":"","title":"Launch JupyterLab"},{"location":"python/#standard-launch","text":"jupyter lab JupyterLab should open in your browser (or print a local URL like http://localhost:8888/lab you can click). Stop JupyterLab: go back to the terminal where it\u2019s running and press Ctrl+C (twice if needed), then confirm y if prompted.","title":"Standard launch"},{"location":"python/#use-in-vs-code-alternative-workflow","text":"Install VS Code extensions: Python and Jupyter . Open or create a .ipynb notebook. Click the kernel picker (top right) \u2192 choose Python (qss20) . Run a cell (e.g., print(\"hello\") ).","title":"Use in VS Code (alternative workflow)"},{"location":"python/#common-its-not-working-fixes","text":"jupyter not found: conda activate qss20 then reinstall jupyterlab in the qss20 environment. Wrong env active: conda info --envs , then conda activate qss20 . Multiple Python installs causing confusion: check path order: macOS/Linux: which python and which jupyter Windows: where python and where jupyter Kernel not showing in Jupyter/VS Code: re-run the kernel registration step and then restart Jupyter/VS Code. That\u2019s it\u2014if they can print versions, see the qss20 kernel, and open JupyterLab, the install was successful.","title":"Common \u201cit\u2019s not working\u201d fixes"},{"location":"syllabus/","text":"","title":"\ud83d\udcd6 Syllabus"},{"location":"tools/","text":"Communication \u00b6 Please use course messages instead of emailing the instructor , as other students will likely share your questions and may be able to answer them too. While I will be answering questions within a window of 24 hours, I encourage you to help each other and answer each other\u2019s questions. Computing \u00b6 Locally-installed Python . While cloud computing is common in data science, the baseline for code development is to work locally. So the main interface we will use to code is your own laptop, on which you will install Python and relevant packages. Text editor . You will need this when working with code locally to edit .py scripts, text files, and .yaml files. See instructions below. Git/GitHub for version control . One of the course goals is to get you more familiar with using Git/GitHub for version control. You can interact with GitHub both from your local machine and from the Jhub remote environment. There are instructions below for each, and we\u2019ll have an in-class activity where you create your own repository and add me as a collaborator. Jhub as a remote computing environment . Jonathan Crossett in Dartmouth\u2019s Information, Technology, and Computing has set up a dedicated course server on Dartmouth\u2019s Jupyter Hub (Jhub for short). This allows you to open up any browser and complete Python tutorials without needing to download data or files locally / deal with package installation issues. You will need a local Python installation for this course, but JHub is an acceptable option for early in the quarter and/or a backup if/when you have sticky local installation errors. More details on the server are below. Terminal/terminal emulator . This is mainly for interfacing with Git/GitHub. See instructions below for installation. LaTeX/Overleaf for dynamic typesetting . We\u2019ll be using the LaTeX typesetting software to integrate writing and formulae and more cleanly integrate figures into writeups. We\u2019ll be interacting with LaTeX through an online interface called Overleaf, so please create a free account here . If you want to work with LaTeX offline/locally, try googling \u201chow to install LaTeX\u201d.","title":"Tools Overview"},{"location":"tools/#communication","text":"Please use course messages instead of emailing the instructor , as other students will likely share your questions and may be able to answer them too. While I will be answering questions within a window of 24 hours, I encourage you to help each other and answer each other\u2019s questions.","title":"Communication"},{"location":"tools/#computing","text":"Locally-installed Python . While cloud computing is common in data science, the baseline for code development is to work locally. So the main interface we will use to code is your own laptop, on which you will install Python and relevant packages. Text editor . You will need this when working with code locally to edit .py scripts, text files, and .yaml files. See instructions below. Git/GitHub for version control . One of the course goals is to get you more familiar with using Git/GitHub for version control. You can interact with GitHub both from your local machine and from the Jhub remote environment. There are instructions below for each, and we\u2019ll have an in-class activity where you create your own repository and add me as a collaborator. Jhub as a remote computing environment . Jonathan Crossett in Dartmouth\u2019s Information, Technology, and Computing has set up a dedicated course server on Dartmouth\u2019s Jupyter Hub (Jhub for short). This allows you to open up any browser and complete Python tutorials without needing to download data or files locally / deal with package installation issues. You will need a local Python installation for this course, but JHub is an acceptable option for early in the quarter and/or a backup if/when you have sticky local installation errors. More details on the server are below. Terminal/terminal emulator . This is mainly for interfacing with Git/GitHub. See instructions below for installation. LaTeX/Overleaf for dynamic typesetting . We\u2019ll be using the LaTeX typesetting software to integrate writing and formulae and more cleanly integrate figures into writeups. We\u2019ll be interacting with LaTeX through an online interface called Overleaf, so please create a free account here . If you want to work with LaTeX offline/locally, try googling \u201chow to install LaTeX\u201d.","title":"Computing"},{"location":"vscode/","text":"Install VS Code \u00b6 macOS: Download \u201cApple Silicon\u201d (M-series) or \u201cIntel\u201d build from here and install. Windows: Download the Windows installer from here and install (accept defaults). Tip: After installing, open VS Code once so it registers shell commands. Install Extensions for Python \u00b6 Open VS Code \u2192 Extensions (\u21e7\u2318X / Ctrl+Shift+X) and install: Python (Microsoft) Jupyter (Microsoft) (Optional but nice) Pylance (Microsoft) for fast IntelliSense You can also install via command line: code --install-extension ms-python.python code --install-extension ms-toolsai.jupyter code --install-extension ms-python.vscode-pylance Tell VS Code which interpreter to use \u00b6 Open your project folder in VS Code ( File \u2192 Open Folder ). Press \u2318\u21e7P / Ctrl+Shift+P \u2192 Python: Select Interpreter . Choose the interpreter from your conda environment like qss20 ). If you don\u2019t see it, ensure the env is created and activated once in a terminal, then retry Select Interpreter . Jupyter notebooks in VS Code \u00b6 Create a new file analysis.ipynb (File \u2192 New File \u2192 Jupyter Notebook). At the top right, choose the Kernel \u2192 pick \u201cPython Environments\u201d \u2192 pick your conda environment ( qss20 ). Try a cell: import sys print ( sys . version ) If VS Code asks to install ipykernel , run the following in the terminal: conda activate qss20 conda install jupyterlab notebook ipykernel Then restart VS Code and retry.","title":"VS Code"},{"location":"vscode/#install-vs-code","text":"macOS: Download \u201cApple Silicon\u201d (M-series) or \u201cIntel\u201d build from here and install. Windows: Download the Windows installer from here and install (accept defaults). Tip: After installing, open VS Code once so it registers shell commands.","title":"Install VS Code"},{"location":"vscode/#install-extensions-for-python","text":"Open VS Code \u2192 Extensions (\u21e7\u2318X / Ctrl+Shift+X) and install: Python (Microsoft) Jupyter (Microsoft) (Optional but nice) Pylance (Microsoft) for fast IntelliSense You can also install via command line: code --install-extension ms-python.python code --install-extension ms-toolsai.jupyter code --install-extension ms-python.vscode-pylance","title":"Install Extensions for Python"},{"location":"vscode/#tell-vs-code-which-interpreter-to-use","text":"Open your project folder in VS Code ( File \u2192 Open Folder ). Press \u2318\u21e7P / Ctrl+Shift+P \u2192 Python: Select Interpreter . Choose the interpreter from your conda environment like qss20 ). If you don\u2019t see it, ensure the env is created and activated once in a terminal, then retry Select Interpreter .","title":"Tell VS Code which interpreter to use"},{"location":"vscode/#jupyter-notebooks-in-vs-code","text":"Create a new file analysis.ipynb (File \u2192 New File \u2192 Jupyter Notebook). At the top right, choose the Kernel \u2192 pick \u201cPython Environments\u201d \u2192 pick your conda environment ( qss20 ). Try a cell: import sys print ( sys . version ) If VS Code asks to install ipykernel , run the following in the terminal: conda activate qss20 conda install jupyterlab notebook ipykernel Then restart VS Code and retry.","title":"Jupyter notebooks in VS Code"},{"location":"homework/hw1/","text":"Due : Monday 9/29 at 11:59 pm Files: GitHub Repo Directory Submission: Gradescope , submit in Groups of 1-3 Corrections & Clarifications \u00b6 1.2.2 : Try to do so efficiently (e.g., write a function and apply to a column, rather than edit the variable repeatedly in separate line for each recoded offense) 1.3 : Create sentenceymd_derived that\u2019s a version of SENTENCE_DATE converted to datetime format. Also create a rounded version, sentenceym_derived , that\u2019s rounded down to the first day of the month (e.g., 1/5/2016 would become 1/1/2016 and 3/27/2018 would become 3/1/2018 ) How to Submit \u00b6 Prepare Your Notebook \u00b6 Open your .ipynb file (JupyterLab, VS Code). Run all cells so outputs are visible: JupyterLab: Kernel \u2192 Restart Kernel and Run All Cells VS Code: Restart \u2192 Run All Save the notebook so outputs are stored in the .ipynb . Convert Your Notebook to PDF \u00b6 Choose one method below: Jupyter Lab built-in File \u2192 Save and Export Notebook As \u2192 PDF (If you see LaTeX errors, use one of the alternatives below.) VS Code ... \u2192 Export \u2192 PDF (or press Cmd+Shift+P (Mac)/ Ctrl+Shift+P (Windows) and select Jupyter: Export to PDF ). Command line ( nbconvert ) HTML \u2192 Browser \u2192 Print as PDF (no LaTeX needed but code can get cut off): jupyter nbconvert --to html your_notebook.ipynb # then open the generated .html in a browser and Print \u2192 Save as PDF Direct PDF (requires LaTeX): jupyter nbconvert --to pdf your_notebook.ipynb Before moving on: confirm the PDF shows all code, text, and output. Submit TWO Files on Gradescope \u00b6 Log in to Gradescope , you will see two assignments for this problem set. Upload both .ipynb and .pdf files: Assignment PS01 - ipynb : The .ipynb file (with saved outputs). Assignment PS01 - PDF : The .pdf file you just created. If prompted to Match pages to questions : Click Assign and map the correct page(s) to each question. Ensure all questions are assigned. Add Your Group Members \u00b6 After uploading, click Group Members at the bottom. Search and add all teammates enrolled in the course. Confirm everyone is listed\u2014Gradescope will share the submission and grade. Final Checks \u00b6 Open the submitted PDF preview to confirm everything looks correct. Verify you submitted both the .ipynb and .pdf files. Verify all your group members are listed. If something is wrong, feel free to resubmit before the deadline.","title":"Problem Set 1: Analysis of Racial Disparities in Felony Sentencing"},{"location":"homework/hw1/#corrections-clarifications","text":"1.2.2 : Try to do so efficiently (e.g., write a function and apply to a column, rather than edit the variable repeatedly in separate line for each recoded offense) 1.3 : Create sentenceymd_derived that\u2019s a version of SENTENCE_DATE converted to datetime format. Also create a rounded version, sentenceym_derived , that\u2019s rounded down to the first day of the month (e.g., 1/5/2016 would become 1/1/2016 and 3/27/2018 would become 3/1/2018 )","title":"Corrections &amp; Clarifications"},{"location":"homework/hw1/#how-to-submit","text":"","title":"How to Submit"},{"location":"homework/hw1/#prepare-your-notebook","text":"Open your .ipynb file (JupyterLab, VS Code). Run all cells so outputs are visible: JupyterLab: Kernel \u2192 Restart Kernel and Run All Cells VS Code: Restart \u2192 Run All Save the notebook so outputs are stored in the .ipynb .","title":"Prepare Your Notebook"},{"location":"homework/hw1/#convert-your-notebook-to-pdf","text":"Choose one method below: Jupyter Lab built-in File \u2192 Save and Export Notebook As \u2192 PDF (If you see LaTeX errors, use one of the alternatives below.) VS Code ... \u2192 Export \u2192 PDF (or press Cmd+Shift+P (Mac)/ Ctrl+Shift+P (Windows) and select Jupyter: Export to PDF ). Command line ( nbconvert ) HTML \u2192 Browser \u2192 Print as PDF (no LaTeX needed but code can get cut off): jupyter nbconvert --to html your_notebook.ipynb # then open the generated .html in a browser and Print \u2192 Save as PDF Direct PDF (requires LaTeX): jupyter nbconvert --to pdf your_notebook.ipynb Before moving on: confirm the PDF shows all code, text, and output.","title":"Convert Your Notebook to PDF"},{"location":"homework/hw1/#submit-two-files-on-gradescope","text":"Log in to Gradescope , you will see two assignments for this problem set. Upload both .ipynb and .pdf files: Assignment PS01 - ipynb : The .ipynb file (with saved outputs). Assignment PS01 - PDF : The .pdf file you just created. If prompted to Match pages to questions : Click Assign and map the correct page(s) to each question. Ensure all questions are assigned.","title":"Submit TWO Files on Gradescope"},{"location":"homework/hw1/#add-your-group-members","text":"After uploading, click Group Members at the bottom. Search and add all teammates enrolled in the course. Confirm everyone is listed\u2014Gradescope will share the submission and grade.","title":"Add Your Group Members"},{"location":"homework/hw1/#final-checks","text":"Open the submitted PDF preview to confirm everything looks correct. Verify you submitted both the .ipynb and .pdf files. Verify all your group members are listed. If something is wrong, feel free to resubmit before the deadline.","title":"Final Checks"},{"location":"staff/","text":"Instructor \u00b6 Office Hours Wed 3:30-4pm Fri 3:30-4pm Silsby 123 Keng-Chi Chang he/him kengchichang@dartmouth.edu Hey, I\u2019m Keng-Chi! I am an Assistant Professor in Quantitative Social Science at Dartmouth. I use computational tools, including AI and Large Language Models, to study how technology and media influence politics. My work explores censorship circumvention, online image-sharing behavior, and how short-form video content are recommended by algorithms. I\u2019m fascinated by the ways our digital world is reshaping democracy and the possibilities\u2014and risks\u2014it creates for our social life. Outside of work, I love hiking, arthouse movies, and cooking Taiwanese food. Computing Support \u00b6 Office Hours Schedule Here Grace Aronson she/her Grace.R.Aronsohn@dartmouth.edu The Social Science Data Lab is an initiative that advances data-driven research in the social sciences by acting as a resource for students and faculty in Economics, Government, and Quantitative Social Science. The SSDL provides comprehensive support throughout the quantitative research process, from initial planning and design to final analysis, interpretation, and presentation. The lab is staffed by Data Scientists proficient in Python, R, and Stata. Feel free to seek out help for assignments and your final project.","title":"Staff / Office Hours"},{"location":"staff/#instructor","text":"Office Hours Wed 3:30-4pm Fri 3:30-4pm Silsby 123 Keng-Chi Chang he/him kengchichang@dartmouth.edu Hey, I\u2019m Keng-Chi! I am an Assistant Professor in Quantitative Social Science at Dartmouth. I use computational tools, including AI and Large Language Models, to study how technology and media influence politics. My work explores censorship circumvention, online image-sharing behavior, and how short-form video content are recommended by algorithms. I\u2019m fascinated by the ways our digital world is reshaping democracy and the possibilities\u2014and risks\u2014it creates for our social life. Outside of work, I love hiking, arthouse movies, and cooking Taiwanese food.","title":"Instructor"},{"location":"staff/#computing-support","text":"Office Hours Schedule Here Grace Aronson she/her Grace.R.Aronsohn@dartmouth.edu The Social Science Data Lab is an initiative that advances data-driven research in the social sciences by acting as a resource for students and faculty in Economics, Government, and Quantitative Social Science. The SSDL provides comprehensive support throughout the quantitative research process, from initial planning and design to final analysis, interpretation, and presentation. The lab is staffed by Data Scientists proficient in Python, R, and Stata. Feel free to seek out help for assignments and your final project.","title":"Computing Support"}]}